"""
OSM ê¸°ë°˜ NYC Brooklyn ë„ë¡œ ë„¤íŠ¸ì›Œí¬ ì‹œê°í™” (v3 - ê°œì„ ëœ ë²„ì „)
- GNN í† í´ë¡œì§€ ì—°ê²° + ì´ë™ì‹œê°„ í–‰ë ¬ ë™ì‹œ ê³ ë ¤
- ë‘ ì œì•½ì¡°ê±´ì„ ëª¨ë‘ ë§Œì¡±í•˜ëŠ” ìµœì  í´ëŸ¬ìŠ¤í„°-ì¡´ ë§¤í•‘
"""

import json
import numpy as np
import matplotlib.pyplot as plt
from matplotlib.patches import FancyArrowPatch
import warnings
warnings.filterwarnings('ignore')
from scipy.optimize import linear_sum_assignment
from scipy.spatial.distance import cdist
from itertools import permutations

def check_dependencies():
    """í•„ìš”í•œ íŒ¨í‚¤ì§€ í™•ì¸"""
    missing = []
    try:
        import osmnx
    except ImportError:
        missing.append('osmnx')
    try:
        from sklearn.cluster import KMeans
    except ImportError:
        missing.append('scikit-learn')
    
    if missing:
        print(f"âš ï¸ í•„ìš”í•œ íŒ¨í‚¤ì§€ê°€ ì—†ìŠµë‹ˆë‹¤: {missing}")
        return False
    return True

def download_brooklyn_network(use_cache=True):
    """OpenStreetMapì—ì„œ Brooklyn ë„ë¡œ ë„¤íŠ¸ì›Œí¬ ë¡œë“œ"""
    import osmnx as ox
    
    cache_file = 'figures/brooklyn_network.graphml'
    
    if use_cache:
        try:
            import os
            if os.path.exists(cache_file):
                print("ğŸ“‚ ìºì‹œëœ ë„¤íŠ¸ì›Œí¬ ë¡œë”©...")
                return ox.load_graphml(cache_file)
        except Exception as e:
            print(f"ìºì‹œ ë¡œë”© ì‹¤íŒ¨: {e}")
    
    print("ğŸŒ Brooklyn ë„ë¡œë§ ë‹¤ìš´ë¡œë“œ ì¤‘...")
    G = ox.graph_from_place("Brooklyn, New York City, New York, USA", 
                            network_type='drive', simplify=True)
    import os
    os.makedirs('figures', exist_ok=True)
    ox.save_graphml(G, cache_file)
    return G


def extract_edge_centroids(G):
    """ë„ë¡œ ë§í¬ ì¤‘ì‹¬ì  ì¶”ì¶œ"""
    nodes = {node: (data['y'], data['x']) for node, data in G.nodes(data=True)}
    centroids = []
    edge_list = []
    
    for u, v, key, data in G.edges(keys=True, data=True):
        lat1, lon1 = nodes[u]
        lat2, lon2 = nodes[v]
        centroids.append(((lat1 + lat2) / 2, (lon1 + lon2) / 2))
        edge_list.append((u, v, key))
    
    return np.array(centroids), edge_list


def cluster_edges_kmeans(centroids, n_clusters=14):
    """K-means í´ëŸ¬ìŠ¤í„°ë§"""
    from sklearn.cluster import KMeans
    
    print(f"ğŸ”„ K-means í´ëŸ¬ìŠ¤í„°ë§ ({n_clusters}ê°œ ì¡´)...")
    kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)
    labels = kmeans.fit_predict(centroids)
    return labels, kmeans.cluster_centers_


def load_scenario_data():
    """ì‹œë‚˜ë¦¬ì˜¤ ë°ì´í„° ë¡œë“œ"""
    with open('src/envs/data/macro/scenario_nyc_brooklyn.json', 'r') as f:
        return json.load(f)


def build_gnn_adjacency(scenario_data):
    """
    GNN í† í´ë¡œì§€ ê·¸ë˜í”„ì—ì„œ ì¸ì ‘ í–‰ë ¬ êµ¬ì¶•
    """
    topology = scenario_data.get('topology_graph', [])
    n_zones = 14
    adj = np.zeros((n_zones, n_zones), dtype=int)
    
    for edge in topology:
        adj[edge['i'], edge['j']] = 1
    
    print(f"ğŸ“Š GNN í† í´ë¡œì§€: {len(topology)}ê°œ ì—£ì§€")
    return adj


def build_travel_time_matrix(scenario_data):
    """ì¡´ ê°„ í‰ê·  ì´ë™ ì‹œê°„ í–‰ë ¬ ìƒì„±"""
    import pandas as pd
    
    df = pd.DataFrame(scenario_data['demand'])
    avg_tt = df.groupby(['origin', 'destination'])['travel_time'].mean().reset_index()
    
    n_zones = 14
    tt_matrix = np.full((n_zones, n_zones), np.inf)
    
    for _, row in avg_tt.iterrows():
        o, d = int(row['origin']), int(row['destination'])
        if o < n_zones and d < n_zones:
            tt_matrix[o, d] = row['travel_time']
    
    # ëŒ€ì¹­í™”
    for i in range(n_zones):
        for j in range(i+1, n_zones):
            min_tt = min(tt_matrix[i, j], tt_matrix[j, i])
            if min_tt != np.inf:
                tt_matrix[i, j] = min_tt
                tt_matrix[j, i] = min_tt
    
    np.fill_diagonal(tt_matrix, 0)
    return tt_matrix


def build_cluster_adjacency(cluster_centers, threshold_percentile=25):
    """
    í´ëŸ¬ìŠ¤í„° ì¤‘ì‹¬ ê°„ ê±°ë¦¬ë¡œ ì¸ì ‘ êµ¬ì¡° ì¶”ì •
    - ê°€ê¹Œìš´ í´ëŸ¬ìŠ¤í„°ë¼ë¦¬ ì¸ì ‘í•œ ê²ƒìœ¼ë¡œ ê°„ì£¼
    """
    n_clusters = len(cluster_centers)
    distances = cdist(cluster_centers, cluster_centers, metric='euclidean')
    
    # ìê¸° ìì‹  ì œì™¸í•˜ê³  threshold ê³„ì‚°
    mask = ~np.eye(n_clusters, dtype=bool)
    threshold = np.percentile(distances[mask], threshold_percentile)
    
    adj = (distances < threshold) & mask
    return adj.astype(int), distances


def compute_mapping_cost(mapping, gnn_adj, cluster_adj, tt_matrix, cluster_distances):
    """
    ì£¼ì–´ì§„ ë§¤í•‘ì˜ ë¹„ìš© ê³„ì‚°
    
    ë¹„ìš© = Î± * (GNN ì¸ì ‘ì„± ë¶ˆì¼ì¹˜) + Î² * (ì´ë™ì‹œê°„ íŒ¨í„´ ë¶ˆì¼ì¹˜)
    """
    n = len(mapping)
    
    # 1. GNN ì¸ì ‘ì„± ë¹„ìš©: ì—°ê²°ëœ ì¡´ë“¤ì´ ì¸ì ‘í•œ í´ëŸ¬ìŠ¤í„°ì— ë§¤í•‘ë˜ì—ˆëŠ”ì§€
    adj_cost = 0
    for zone_i in range(n):
        for zone_j in range(n):
            if gnn_adj[zone_i, zone_j] == 1:  # GNNì—ì„œ ì—°ê²°ëœ ì¡´
                cluster_i = mapping[zone_i]
                cluster_j = mapping[zone_j]
                if cluster_adj[cluster_i, cluster_j] != 1:  # í´ëŸ¬ìŠ¤í„°ê°€ ì¸ì ‘í•˜ì§€ ì•Šìœ¼ë©´ íŒ¨ë„í‹°
                    adj_cost += 1
    
    # 2. ì´ë™ì‹œê°„ íŒ¨í„´ ë¹„ìš©: ì¡´ ê°„ ì´ë™ì‹œê°„ê³¼ í´ëŸ¬ìŠ¤í„° ê°„ ê±°ë¦¬ì˜ ìƒê´€ê´€ê³„
    tt_cost = 0
    tt_norm = tt_matrix.copy()
    tt_norm[tt_norm == np.inf] = np.nanmax(tt_matrix[tt_matrix < np.inf]) * 2 if np.any(tt_matrix < np.inf) else 100
    tt_norm = tt_norm / (tt_norm.max() + 1e-10)
    
    dist_norm = cluster_distances / (cluster_distances.max() + 1e-10)
    
    for zone_i in range(n):
        for zone_j in range(n):
            if zone_i != zone_j:
                cluster_i = mapping[zone_i]
                cluster_j = mapping[zone_j]
                tt_cost += abs(tt_norm[zone_i, zone_j] - dist_norm[cluster_i, cluster_j])
    
    # ê°€ì¤‘ì¹˜ ì¡°í•©
    alpha = 10.0  # GNN ì—°ê²° ê°€ì¤‘ì¹˜ (ë” ì¤‘ìš”)
    beta = 1.0   # ì´ë™ì‹œê°„ ê°€ì¤‘ì¹˜
    
    total_cost = alpha * adj_cost + beta * tt_cost
    return total_cost, adj_cost, tt_cost


def optimize_mapping_greedy(gnn_adj, cluster_adj, tt_matrix, cluster_distances, max_iterations=1000):
    """
    Greedy + Local Searchë¡œ ìµœì  ë§¤í•‘ ì°¾ê¸°
    """
    import random
    n = 14
    
    print("ğŸ” ìµœì  ë§¤í•‘ íƒìƒ‰ ì¤‘...")
    
    # ì´ˆê¸° ë§¤í•‘: ë¬´ì‘ìœ„
    best_mapping = list(range(n))
    random.shuffle(best_mapping)
    best_cost, _, _ = compute_mapping_cost(best_mapping, gnn_adj, cluster_adj, tt_matrix, cluster_distances)
    
    # ë‹¤ì¤‘ ì‹œì‘ì 
    for start in range(20):
        current_mapping = list(range(n))
        random.shuffle(current_mapping)
        current_cost, _, _ = compute_mapping_cost(current_mapping, gnn_adj, cluster_adj, tt_matrix, cluster_distances)
        
        # Local search: 2-opt swap
        improved = True
        iterations = 0
        
        while improved and iterations < max_iterations:
            improved = False
            iterations += 1
            
            for i in range(n):
                for j in range(i+1, n):
                    # Swap zone i and zone j's cluster assignments
                    new_mapping = current_mapping.copy()
                    new_mapping[i], new_mapping[j] = new_mapping[j], new_mapping[i]
                    
                    new_cost, _, _ = compute_mapping_cost(new_mapping, gnn_adj, cluster_adj, tt_matrix, cluster_distances)
                    
                    if new_cost < current_cost:
                        current_mapping = new_mapping
                        current_cost = new_cost
                        improved = True
                        break
                if improved:
                    break
        
        if current_cost < best_cost:
            best_cost = current_cost
            best_mapping = current_mapping.copy()
    
    # zone_id -> cluster_id ë§¤í•‘ ìƒì„±
    zone_to_cluster = {zone: cluster for zone, cluster in enumerate(best_mapping)}
    cluster_to_zone = {cluster: zone for zone, cluster in enumerate(best_mapping)}
    
    final_cost, adj_cost, tt_cost = compute_mapping_cost(best_mapping, gnn_adj, cluster_adj, tt_matrix, cluster_distances)
    
    print(f"âœ… ìµœì  ë§¤í•‘ ì™„ë£Œ:")
    print(f"   - ì´ ë¹„ìš©: {final_cost:.2f}")
    print(f"   - GNN ì¸ì ‘ì„± ë¶ˆì¼ì¹˜: {adj_cost}")
    print(f"   - ì´ë™ì‹œê°„ íŒ¨í„´ ë¹„ìš©: {tt_cost:.2f}")
    
    return cluster_to_zone


def visualize_network_with_zones(G, edge_labels, cluster_centers, cluster_to_zone, gnn_adj, od_flows, output_path='figures/brooklyn_osm_zones_v3.png'):
    """ì‹œê°í™”"""
    import osmnx as ox
    import matplotlib.patches as mpatches
    
    print("ğŸ¨ ì‹œê°í™” ìƒì„± ì¤‘...")
    
    fig, ax = plt.subplots(figsize=(16, 14))
    
    cmap = plt.cm.get_cmap('tab20', 14)
    colors = [cmap(i) for i in range(14)]
    
    edge_colors = []
    for i, (u, v, key) in enumerate(G.edges(keys=True)):
        cluster = edge_labels[i] if i < len(edge_labels) else 0
        zone = cluster_to_zone.get(cluster, 0)
        edge_colors.append(colors[zone])
    
    ox.plot_graph(G, ax=ax, node_size=0, edge_color=edge_colors, 
                  edge_linewidth=0.5, edge_alpha=0.7, show=False, close=False)
    
    # ì¡´ ë¼ë²¨ í‘œì‹œ
    for cluster_idx, center in enumerate(cluster_centers):
        zone_id = cluster_to_zone.get(cluster_idx, cluster_idx)
        lat, lon = center
        ax.plot(lon, lat, 'o', markersize=25, color=colors[zone_id], 
                markeredgecolor='black', markeredgewidth=2, zorder=10)
        ax.text(lon, lat, str(zone_id), fontsize=11, fontweight='bold',
                ha='center', va='center', color='white', zorder=11)
    
    # GNN ì—°ê²° í‘œì‹œ (íŒŒë€ìƒ‰ ì‹¤ì„ )
    zone_to_cluster = {v: k for k, v in cluster_to_zone.items()}
    for zone_i in range(14):
        for zone_j in range(zone_i+1, 14):
            if gnn_adj[zone_i, zone_j] == 1 or gnn_adj[zone_j, zone_i] == 1:
                if zone_i in zone_to_cluster and zone_j in zone_to_cluster:
                    c_i = cluster_centers[zone_to_cluster[zone_i]]
                    c_j = cluster_centers[zone_to_cluster[zone_j]]
                    ax.plot([c_i[1], c_j[1]], [c_i[0], c_j[0]], 
                            'b-', linewidth=1.5, alpha=0.5, zorder=4)
    
    # OD Flow í™”ì‚´í‘œ (ìƒìœ„ 10ê°œ, ë¹¨ê°„ìƒ‰)
    sorted_flows = sorted(od_flows.items(), key=lambda x: x[1], reverse=True)[:10]
    for (origin, dest), flow in sorted_flows:
        if origin != dest and origin < 14 and dest < 14:
            if origin in zone_to_cluster and dest in zone_to_cluster:
                o_center = cluster_centers[zone_to_cluster[origin]]
                d_center = cluster_centers[zone_to_cluster[dest]]
                arrow = FancyArrowPatch(
                    (o_center[1], o_center[0]), (d_center[1], d_center[0]),
                    arrowstyle='-|>', mutation_scale=12,
                    linewidth=max(1, np.log1p(flow) * 0.5),
                    color='red', alpha=0.7, zorder=6)
                ax.add_patch(arrow)
    
    legend_patches = [mpatches.Patch(color=colors[i], label=f'Zone {i}') for i in range(14)]
    legend_patches.append(mpatches.Patch(color='blue', label='GNN Edge'))
    legend_patches.append(mpatches.Patch(color='red', label='Top OD Flow'))
    ax.legend(handles=legend_patches, loc='upper left', ncol=2, fontsize=8)
    
    ax.set_title('NYC Brooklyn Road Network\nOptimized Zone Mapping (GNN Topology + Travel Time)', 
                 fontsize=14, fontweight='bold')
    
    plt.tight_layout()
    plt.savefig(output_path, dpi=300, bbox_inches='tight')
    print(f"âœ… ì €ì¥ë¨: {output_path}")
    plt.close()
    
    return output_path


def main():
    print("=" * 60)
    print("OSM Brooklyn ì‹œê°í™” v3")
    print("GNN í† í´ë¡œì§€ + ì´ë™ì‹œê°„ ë™ì‹œ ê³ ë ¤")
    print("=" * 60)
    
    if not check_dependencies():
        return
    
    # 1. ë„ë¡œ ë„¤íŠ¸ì›Œí¬ ë¡œë“œ
    G = download_brooklyn_network(use_cache=True)
    print(f"ğŸ“Š ë„¤íŠ¸ì›Œí¬: {G.number_of_nodes()} ë…¸ë“œ, {G.number_of_edges()} ì—£ì§€")
    
    # 2. í´ëŸ¬ìŠ¤í„°ë§
    centroids, edge_list = extract_edge_centroids(G)
    labels, cluster_centers = cluster_edges_kmeans(centroids, n_clusters=14)
    
    # 3. ì‹œë‚˜ë¦¬ì˜¤ ë°ì´í„° ë¡œë“œ
    scenario_data = load_scenario_data()
    
    # 4. GNN ì¸ì ‘ í–‰ë ¬
    gnn_adj = build_gnn_adjacency(scenario_data)
    
    # 5. ì´ë™ì‹œê°„ í–‰ë ¬
    tt_matrix = build_travel_time_matrix(scenario_data)
    
    # 6. í´ëŸ¬ìŠ¤í„° ì¸ì ‘ êµ¬ì¡°
    cluster_adj, cluster_distances = build_cluster_adjacency(cluster_centers)
    
    # 7. ìµœì  ë§¤í•‘ íƒìƒ‰
    cluster_to_zone = optimize_mapping_greedy(gnn_adj, cluster_adj, tt_matrix, cluster_distances)
    
    print("\nğŸ“ ìµœì¢… ë§¤í•‘ ê²°ê³¼:")
    for c, z in sorted(cluster_to_zone.items(), key=lambda x: x[1]):
        print(f"   í´ëŸ¬ìŠ¤í„° {c} â†’ ì¡´ {z}")
    
    # 8. OD íë¦„
    import pandas as pd
    df = pd.DataFrame(scenario_data['demand'])
    od_flows = df.groupby(['origin', 'destination'])['demand'].sum().to_dict()
    
    # 9. ì‹œê°í™”
    output_path = visualize_network_with_zones(
        G, labels, cluster_centers, cluster_to_zone, gnn_adj, od_flows
    )
    
    print("=" * 60)
    print("ğŸ‰ ì™„ë£Œ!")
    print("=" * 60)
    return output_path


if __name__ == "__main__":
    main()
